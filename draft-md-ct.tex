% ==================================================
% ========== Draft: Mirror Descent in Continuous Time
% ==================================================
% Last modified: 2017 February 01


\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amscd,amsthm}
\usepackage{mathdef-omar}
\usepackage{enumitem}


% ========== Pstricks
%\usepackage{pst-all}


% ========== Page formats
\setlength{\oddsidemargin}{1.5cm}
\setlength{\textwidth}{14cm}
\setlength{\topmargin}{-.5cm}
\setlength{\textheight}{22cm}


% ========== Theorem-like stuff
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{coro}{Corollary}
\newtheorem{propo}{Proposition}
\newtheorem*{claim}{Claim}
%
\theoremstyle{definition}
\newtheorem{defi}{Definition}
\newtheorem{example}{Example}
%
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{remarks}{Remarks}
\newtheorem*{note}{Note}
\newtheorem*{notes}{Notes}
\newtheorem*{notation}{Notation}
\newtheorem*{notations}{Notations}
%
\newtheorem{fact}[theorem]{Fact}
\newtheorem{exercise}[theorem]{Exercise}
%
\renewcommand{\proof}{\noindent {\sc Proof.}\quad}
\renewcommand{\qedsymbol}{$\blacksquare$}
% ==========





\begin{document}  % ========== BEGIN DOCUMENT

Some calculations about the mirror descent (MD) algorithm.

\bigskip

\noindent
The setting and notations...
\begin{itemize}[leftmargin=*, itemsep=2pt]
\item The potential $R : \R^d \to \R$, a Legendre function.
\item Its convex conjugate: $R^{*}(u) = \sup_{x} \{ \ab{u,x} - R(x)\}$.
\item The ``mirror maps'' $\nabla R : \R^d \to \R^d$ and $\nabla R^{*} : \R^d \to \R^d$.
\item The loss functions $(\ell_t)$, each $\ell_t : \R^d \to \R$.
\item Time index $t \in \{ 0,1,2,\ldots \}$ for discrete time, $t \in [0,\infty)$ for continuous time.
\item $x$, $x_t$ (discrete time), $x(t)$ (continuous time) elements of the primal space.
\item $u$, $u_t$ (discrete time), $u(t)$ (continuous time) elements of the dual space.
\end{itemize}
The MD algorithm (discrete time) uses the initialization and updates
\begin{align}
x_1 &= \arg\min R(x)\,, \label{eq.dtime.md1} \tag{1md} \\
x_{t+1} &= \arg\min_{x \in \R^d} \Bigl\{ \eta \ab{\nabla\ell_t(x_{t}), x} + D_{R}(x, x_{t})\Bigr\}\,.
 \label{eq.dtime.md2} 
\tag{2md}
\end{align}
Here $D_{R}(x,y)$ stands for the Bregman divergence, whose definition is recalled now:
\[
D_{R}(a_{1}, a_{2}) = R(a_{1}) - R(a_{2}) - \ab{\nabla R(a_2), a_{1} - a_{2}}\,.
\]
The order of the arguments matters.
Let's say $D_{R}(a_{1},a_{2})$ is ``supported at $a_{2}$''
(its definition uses a tangent supported at $a_{2}$).
To minimize clutter let's denote by $\partial_{i}$ the partial derivative (operator)
with respect to the $i$-th argument. So for instance:
\begin{align*}
\partial_{1} D_{R}(a_{1}, a_{2}) &= \nabla R(a_{1}) - \nabla R(a_{2})\,, \\[1mm]
\partial_{2} D_{R}(a_{1}, a_{2}) &= - \nabla^2 R(a_{2})(a_{1} - a_{2})\,.
\end{align*}
The equations \eqref{eq.dtime.md1}--\eqref{eq.dtime.md2} are equivalent to:
\begin{align*}
u_{t+1} &= u_{t} - \eta \nabla \ell_{t}(x_{t}) \label{eq.dtime.1} \tag{1dt} \\
x_{t} &= \nabla R^{*}(u_{t})\,. \label{eq.dtime.2} \tag{2dt}
\end{align*}
Analogous equations in continuous time:
\begin{align*}
\dot{u}(t) &= - \eta \nabla \ell_{t}(x(t)) \label{eq.ctime.1} \tag{1ct} \\
x(t) &= \nabla R^{*}(u(t))\,. \label{eq.ctime.2} \tag{2ct}
\end{align*}
For fixed $x^{*} \in \R^d$, $u^{*} = \nabla R(x^{*})$,
\setcounter{equation}{3}
\begin{equation}
\ell_{t}(x^{*}) \geq \ell_{t}(x(t)) + \ab{\nabla\ell_t(x(t)), x^{*} - x(t)} \label{eq.linearizing.loss}
\end{equation}
From \eqref{eq.ctime.1} we get $\nabla \ell_{t}(x(t)) = -\dot{u}(t)/\eta$,
and plugging this in \eqref{eq.linearizing.loss} we get:
\[
\ell_{t}(x^{*}) \geq \ell_{t}(x(t)) - \frac{1}{\eta} \ab{\dot{u}(t), x^{*} - x(t)}\,.
\]
Rearranging:
\begin{equation}
\ell_{t}(x(t)) - \ell_{t}(x^{*}) \leq  \frac{1}{\eta} \ab{\dot{u}(t), x^{*} - x(t)}\,, \label{eq.loss.prep}
\end{equation}
and the claim is that the RHS is the derivative of a Bregman divergence.

\bigskip

On one hand, by the chain rule and the symmetry of the Hessian:
\begin{align*}
\frac{d}{dt} D_{R^{*}}(u^{*}, u(t))
&= \ab{ \partial_{2} D_{R^{*}}(u^{*}, u(t)), \dot{u}(t)} \\[1mm]
&= - \ab{ \nabla^2 R^{*}(u(t))(u^{*} -u(t)), \dot{u}(t) } \\[1mm]
&= - \ab{ u^{*} -u(t), \nabla^2 R^{*}(u(t)) \dot{u}(t) } \\[1mm]
&= - \ab{u^{*} - u(t), \dot{x}(t)}\,.
\end{align*}
On the other hand,
\begin{align*}
\frac{d}{dt} \ab{u^{*} - u(t), x^{*} - x(t)}
&= - \ab{ \dot{u}(t), x^{*} - x(t)} - \ab{ u^{*} -u(t), \dot{x}(t) }\,.
\end{align*}
Combining the two:
\begin{align*}
\ab{ \dot{u}(t), x^{*} - x(t)}
&= - \ab{ u^{*} -u(t), \dot{x}(t) } - \frac{d}{dt} \ab{u^{*} - u(t), x^{*} - x(t)} \\[1mm]
%&= \frac{d}{dt} D_{R^{*}}(u^{*}, u(t)) - \frac{d}{dt} \ab{u^{*} - u(t), x^{*} - x(t)}\,.
&= \frac{d}{dt} \Bigl( D_{R^{*}}(u^{*}, u(t)) - \ab{u^{*} - u(t), x^{*} - x(t)} \Bigr)\,.
\end{align*}
Note that the term
$\ab{u^{*} - u(t), x^{*} - x(t)} = \ab{\nabla R(x^{*}) - \nabla R(x(t)), x^{*} - x(t)}$
is the sum of $D_{R}(x^{*}, x(t))$ and $D_{R}(x(t), x^{*})$.
This is a general property of Bregman divergences that can be obtained directly from the definition:
$$
D_{R}(a_{1}, a_{2}) + D_{R}(a_{2}, a_{1})
= \ab{\nabla R(a_{1}) - \nabla R(a_{2}), a_{1} - a_{2}}\,.
$$
Then \eqref{eq.loss.prep} can be written as
\begin{equation*}
\ell_{t}(x(t)) - \ell_{t}(x^{*})
\leq  \frac{1}{\eta} \frac{d}{dt} \Bigl( D_{R^{*}}(u^{*}, u(t)) - D_{R}(x^{*}, x(t)) - D_{R}(x(t), x^{*})\Bigr)\,.
\end{equation*}
After integrating:
\begin{align*}
\int_{0}^{T} [\ell_{t}(x(t)) - \ell_{t}(x^{*})] dt
&\leq \frac{1}{\eta} \bigl[ D_{R^{*}}(u^{*}, u(T)) - D_{R}(x^{*}, x(T)) - D_{R}(x(T), x^{*}) \\
&\hspace{10mm}- D_{R^{*}}(u^{*}, u(0)) + D_{R}(x^{*}, x(0)) + D_{R}(x(0), x^{*}) \bigr]
\end{align*}

Note: Follow the regularized leader (FTRL) is equivalent to mirror descent when $R$ is a Legendre function
(unconstrained ``optimization'').
Hence, the above result is applicable to both MD and FTRL in this case.

However, when $R$ is not Legendre (constrained case), they will generally be different.



\newpage

Some more calculations, based on the approach of \cite{Kwon-M}.

\bigskip

\noindent
Let's put 
$\displaystyle y(t) = \int_{0}^{t} \dot{u}(s) ds = -\eta \int_{0}^{t} \nabla\ell_{s}(x(s)) ds$.
Then for a fixed $x$,
\begin{equation}
\int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), x}
= \frac{\ab{y(t), x}}{\eta}
\leq \frac{R^{*}(y(t)) + R(x)}{\eta}\,.
\label{eq.using.fenchel.ineq}
\end{equation}
But noting that $x(t) = \nabla R^{*}(y(t))$, 
which means that $x(t)$ is the optimizer in the definition of $R^{*}$, then
\begin{align}
\frac{R^{*}(y(t))}{\eta}
&= \frac{\ab{y(t), x(t)} - R(x(t))}{\eta} \notag \\[1mm]
&= \int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), x(t)} ds - \frac{R(x(t))}{\eta}\,.
\label{eq.something}
\end{align}
Consider the function $\varphi(t,x) = \int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), x} ds$.
In particular, with $x$ replaced with $x(t)$ we have
$\varphi(t,x(t)) = \int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), x(t)} ds$.
The time derivative is
\begin{align*}
\frac{d}{dt}\varphi(t,x(t))
&= \dot{\varphi}(t,x(t)) + \frac{\partial}{\partial x} \varphi(t,x(t)) \cdot \dot{x}(t) \\
&= \ab{-\nabla\ell_{t}(x(t)), x(t)} + \int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), \dot{x}(t)} ds \\
&= \ab{-\nabla\ell_{t}(x(t)), x(t)} + \frac{\ab{y(t), \dot{x}(t)}}{\eta}\,.
\end{align*}
Then with integration (note that $\varphi(0,x(0)) = 0$) we get
\begin{align*}
\int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), x(t)} ds 
&= \varphi(t,x(t)) \\
&= \int_{0}^{t} \frac{d}{ds} \varphi(s,x(s)) ds \\
&= \int_{0}^{t} \ab{-\nabla\ell_{s}(x(s)), x(s)} ds 
     + \frac{1}{\eta} \int_{0}^{t} \ab{y(s), \dot{x}(s)} ds\,.
\end{align*}
% omar's note: this last thing needs to be fixed!

%% Picture 
%\psset{unit=1.4pt} \vspace{3mm} \hspace{8cm}
%\pspicture(0,0)(0,0)
%\pspolygon[fillcolor=gray,fillstyle=crosshatch*](0,0)(70,0) (70,50)(0,50)
%\rput(35,25){\psframebox*[framearc=.3]{\parbox[c]{2.5cm}{\footnotesize\centering STEEL PLATE ON ROAD}}}
%\endpspicture


% omar's note: the following to be added back when the above is fixed!
\noindent
So using the linearization trick (see \eqref{eq.linearizing.loss} above),
continuing from \eqref{eq.using.fenchel.ineq} and \eqref{eq.something},
and rearranging we get
\begin{align*}
\int_{0}^{T} [\ell_{t}(x(t)) - \ell_{t}(x^{*})] dt
&\leq \int_{0}^{T} \ab{\nabla\ell_{t}(x(t)), x(t) - x} dt \\
&\leq \frac{R(x) - R(x(T))}{\eta} + \frac{1}{\eta} \int_{0}^{t} \ab{y(s), \dot{x}(s)} ds\,.
\end{align*}

\newpage

\section*{Equivalence between FTRL and MD}

Some notes to clarify the equivalence between 
Follow the Regularized Leader (FTRL) and Mirror Descent (MD) algorithms.

\medskip

The FTRL algorithm (discrete time) uses the initialization and updates
\begin{align}
x_1 &= ??? \label{eq.ftrl1} \tag{1ftrl} \\
x_{t+1} &= \arg\min_{x \in \R^d} \Bigl\{ \eta \Bigab{ \sum_{s=1}^{t} \nabla\ell_s(x_{s}), x} + R(x)\Bigr\}\,.
 \label{eq.ftrl2} 
\tag{2ftrl}
\end{align}
Here $R(x)$ is the regularizer used by FTRL.
To find an explicit form for the optimizer, let
$$
G(x) = \eta \sum_{s=1}^{t} \ab{ \nabla\ell_s(x_{s}), x} + R(x)\,.
$$
Then $\nabla G(x) = \eta \sum_{s=1}^{t} \nabla\ell_s(x_{s}) + \nabla R(x)$
and it is clear that $\nabla G(x) = 0$ 
when $x = \nabla R^{*} \bigl( -\eta \sum_{s=1}^{t} \nabla\ell_s(x_{s}) \bigr)$.
The second derivative $\nabla^2 G(x) = \nabla^2 R(x)$ is positive,
so this point $x$ gives the minimum.
So the update rule \eqref{eq.ftrl2} becomes
$$
x_{t+1} = \nabla R^{*} \bigl( -\eta \sum_{s=1}^{t} \nabla\ell_s(x_{s}) \bigr)\,.
$$
Defining $u_{t+1} = -\eta \sum_{s=1}^{t} \nabla\ell_s(x_{s})$ with $u_{0} = 0$,
we get $u_{t+1} = u_{t} - \eta \nabla\ell_t(x_{t})$,
and the update can be rewritten as the following:
\begin{align*}
u_{t+1} &= u_{t} - \eta \nabla \ell_{t}(x_{t})\,, \\
x_{t+1} &= \nabla R^{*}(u_{t+1})\,. 
\end{align*}
These are clearly the equations \eqref{eq.dtime.1}--\eqref{eq.dtime.2} of MD.

\medskip

Conversely, starting from the equations \eqref{eq.dtime.1}--\eqref{eq.dtime.2} of MD,
we can revert the process and obtain the equations \eqref{eq.ftrl1}--\eqref{eq.ftrl2} of FTRL.

\medskip

\begin{thebibliography}{biblio}

\bibitem{Kwon-M}
  J.~Kwon and P.~Mertikopoulos,
  A continuous-time approach to online optimization.
  Preprint. arXiv:1401.6956.

\bibitem{Warmuth-Jagota}
  M.K.~Warmuth and A.K.~Jagota,
  Continuous and discrete-time nonlinear gradient descent: relative loss bounds and convergence.
  In: 
  \textit{Proc. Fifth International Symposium on Artificial Intelligence and Mathematics}, 1998.


\end{thebibliography}


\vspace{.5cm}


% -------------------------------------------------------
\noindent
Last updated: \today

\end{document}  % ========== END DOCUMENT
